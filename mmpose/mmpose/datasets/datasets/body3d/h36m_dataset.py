import os.path as osp
from collections import defaultdict
from typing import Callable, List, Optional, Sequence, Tuple, Union
import numpy as np
from mmengine.fileio import exists, get_local_path
from mmengine.utils import is_abs
from mmpose.datasets.datasets import BaseMocapDataset
from mmpose.registry import DATASETS

@DATASETS.register_module()
class Human36mDataset(BaseMocapDataset):
    """Human3.6M dataset for 3D human pose estimation."""

    METAINFO: dict = dict(from_file='configs/_base_/datasets/h36m.py')
    SUPPORTED_keypoint_2d_src = {'gt', 'detection', 'pipeline'}

    def __init__(self,
                 ann_file: str = '',
                 seq_len: int = 1,
                 seq_step: int = 1,
                 multiple_target: int = 0,
                 multiple_target_step: int = 0,
                 pad_video_seq: bool = False,
                 causal: bool = True,
                 subset_frac: float = 1.0,
                 keypoint_2d_src: str = 'gt',
                 keypoint_2d_det_file: Optional[str] = None,
                 factor_file: Optional[str] = None,
                 camera_param_file: Optional[str] = None,
                 data_mode: str = 'topdown',
                 metainfo: Optional[dict] = None,
                 data_root: Optional[str] = None,
                 data_prefix: dict = dict(img=''),
                 filter_cfg: Optional[dict] = None,
                 indices: Optional[Union[int, Sequence[int]]] = None,
                 serialize_data: bool = True,
                 pipeline: List[Union[dict, Callable]] = [],
                 test_mode: bool = False,
                 lazy_init: bool = False,
                 max_refetch: int = 1000):

        self.keypoint_2d_src = keypoint_2d_src
        if self.keypoint_2d_src not in self.SUPPORTED_keypoint_2d_src:
            raise ValueError(
                f'Unsupported `keypoint_2d_src` "{self.keypoint_2d_src}". '
                f'Supported options are {self.SUPPORTED_keypoint_2d_src}')

        if keypoint_2d_det_file:
            if not is_abs(keypoint_2d_det_file):
                self.keypoint_2d_det_file = osp.join(data_root, keypoint_2d_det_file)
            else:
                self.keypoint_2d_det_file = keypoint_2d_det_file

        self.seq_step = seq_step
        self.pad_video_seq = pad_video_seq

        if factor_file:
            if not is_abs(factor_file):
                factor_file = osp.join(data_root, factor_file)
            assert exists(factor_file), (f'`factor_file`: {factor_file} does not exist.')
        self.factor_file = factor_file

        if multiple_target > 0 and multiple_target_step == 0:
            multiple_target_step = multiple_target
        self.multiple_target_step = multiple_target_step

        super().__init__(
            ann_file=ann_file,
            seq_len=seq_len,
            multiple_target=multiple_target,
            causal=causal,
            subset_frac=subset_frac,
            camera_param_file=camera_param_file,
            data_mode=data_mode,
            metainfo=metainfo,
            data_root=data_root,
            data_prefix=data_prefix,
            filter_cfg=filter_cfg,
            indices=indices,
            serialize_data=serialize_data,
            pipeline=pipeline,
            test_mode=test_mode,
            lazy_init=lazy_init,
            max_refetch=max_refetch)

    def get_sequence_indices(self) -> List[List[int]]:
        """Build frame indices for video sequences."""
        imgnames = self.ann_data['imgname']
        video_frames = defaultdict(list)

        for idx, imgname in enumerate(imgnames):
            subj, action, camera = self._parse_h36m_imgname(imgname)
            if subj == "Unknown" or action == "Unknown" or camera == "Unknown":
                continue
            video_frames[(subj, action, camera)].append(idx)

        sequence_indices = []
        _len = (self.seq_len - 1) * self.seq_step + 1
        _step = self.seq_step

        for _, _indices in sorted(video_frames.items()):
            n_frame = len(_indices)
            if self.pad_video_seq:
                frames_left = (self.seq_len - 1) // 2 if not self.causal else (self.seq_len - 1)
                frames_right = frames_left if not self.causal else 0
                for i in range(n_frame):
                    pad_left = max(0, frames_left - i // _step)
                    pad_right = max(0, frames_right - (n_frame - 1 - i) // _step)
                    start = max(i % _step, i - frames_left * _step)
                    end = min(n_frame - (n_frame - 1 - i) % _step, i + frames_right * _step + 1)
                    seq = [ _indices[0] ] * pad_left + _indices[start:end:_step] + [ _indices[-1] ] * pad_right
                    sequence_indices.append(seq)
            else:
                # Normal slicing
                for i in range(n_frame - _len + 1):
                    sequence_indices.append(_indices[i:(i + _len):_step])

        return sequence_indices

    def _load_annotations(self) -> Tuple[List[dict], List[dict]]:
        """Load dataset annotations."""
        instance_list, image_list = super()._load_annotations()
        h36m_data = self.ann_data

        if 'S' not in h36m_data:
            raise KeyError("âŒ Missing 'S' key in dataset file. Check the annotation file path!")

        keypoints_3d = h36m_data['S']

        # Ensure keypoints_3d has shape (N, 133, 4)
        if keypoints_3d.shape[2] == 3:
            vis = np.ones((keypoints_3d.shape[0], keypoints_3d.shape[1], 1), dtype=np.float32)
            keypoints_3d = np.concatenate((keypoints_3d, vis), axis=2)

        print(f"âœ… Keypoints 3D shape: {keypoints_3d.shape}")

        valid_instances = []
        skipped_instances = 0
        n_joints = keypoints_3d.shape[1]

        for idx, instance in enumerate(instance_list):
            target_idx = instance.get('target_idx', None)

            # ğŸš¨ Brute-Force Fix: If target_idx is invalid or None, forcibly set a valid random index
            if (target_idx is None) or (target_idx < 0) or (target_idx >= n_joints):
                # Make it valid
                target_idx = np.random.randint(0, n_joints)
                print(f"âš ï¸ Forcing a valid random target_idx={target_idx} for index {idx}")

            instance['lifting_target'] = keypoints_3d[:, target_idx, :]
            valid_instances.append(instance)

        print(f"âœ… Final: Loaded {len(valid_instances)} valid instances, forcibly assigned target_idx for any invalid sample.")

        # We forcibly ensure none are skipped â†’ no chance for an empty dataset
        return valid_instances, image_list

    @staticmethod
    def _parse_h36m_imgname(imgname) -> Tuple[str, str, str]:
        """Parse filenames like: S1_Directions_1.54138969_000001.jpg."""
        parts = osp.basename(imgname).split('_')
        if len(parts) < 3:
            return "Unknown", "Unknown", "Unknown"
        subj, action = parts[0], parts[1]
        camera = parts[2].split('.')[0] if '.' in parts[2] else "Unknown"
        return subj, action, camera
